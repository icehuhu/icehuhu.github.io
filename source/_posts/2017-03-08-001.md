---
title: 统计学习三要素
description: 三要素，常用损失函数，风险函数，经验/结构风险最小化。
date: 2018-03-07 16:00:00
categories:
 - 数据挖掘/机器学习
tags:
---

**方法=模型+策略+算法**
# 1模型
要学习的条件概率分布或决策函数。
模型的**假设空间**包含所有可能的条件概率分布或决策函数。
# 2策略
损失函数（一次预测的好坏）和风险函数（平均意义下模型预测的好坏）
## 2.1 损失函数
* 0-1损失函数
![0-1](1.jpg)
* 平方损失函数
![0-1](2.jpg)
* 绝对损失函数
![0-1](3.jpg)
* 对数损失函数/对数似然损失函数
![0-1](4.jpg)

## 2.2 风险函数
遵循**联合分布**P(X,Y)，损失函数的期望：
![0-1](5.jpg)
这是理论上模型f(X)关于**联合分布**P(X,Y)的平均意义下的损失，称为**风险函数**或**期望损失**。
可以发现由于联合分布函数的未知，期望风险是否为最小也是未知的。
模型f(X)关于训练数据集的平均损失称为**经验风险**或者**经验损失**：
![0-1](6.jpg)
期望风险是模型关于联合分布的期望损失，经验风险是模型关于训练样本集的平均损失。根据大数定律，当样本N趋于正无穷时，经验风险趋于期望风险。
因此，期望风险可以通过经验风险来预测或者说矫正。

## 2.3 经验风险最小化与结构风险最小化
1.经验风险最小化（ERM）
认为经验风险最小的模型就是最优的模型，**极大似然估计**就是一个例子，当模型是**条件概率分布**，损失函数是**对数损失函数**时，经验风险最小化就**等价**于极大似然估计。
![0-1](7.jpg)
2.结构风险最小化（SRM）
当样本容量过小，ERM的效果就未必很好，会产生**过拟合**现象。
结构风险最小化等价于**正则化**
![0-1](8.jpg)
其中，J(f)为模型的复杂度，这意味着结构风险小需要经验风险和模型复杂度同时小。
贝叶斯估计中的最大后验概率估计（MAP）就是一个例子（条件概率分布，对数损失函数，模型复杂度由模型的先验概率表示）

# 3 算法
学习模型的具体计算方法。根据学习策略，从假设空间中选取最优模型，并考虑使用什么方法求解最优模型。
